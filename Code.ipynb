{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:19:56.316643Z",
     "start_time": "2021-12-29T21:19:56.275620Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:19:56.907537Z",
     "start_time": "2021-12-29T21:19:56.893572Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context('talk')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set(font='SimHei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:00.961242Z",
     "start_time": "2021-12-29T21:19:57.307973Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('train.csv')\n",
    "data_test_a = pd.read_csv('testA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:01.526893Z",
     "start_time": "2021-12-29T21:20:01.324870Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:01.901448Z",
     "start_time": "2021-12-29T21:20:01.888483Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Train data shape:', data_train.shape)\n",
    "print('TestA data shape:', data_test_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:02.275450Z",
     "start_time": "2021-12-29T21:20:02.246525Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:02.635485Z",
     "start_time": "2021-12-29T21:20:02.622520Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:03.207473Z",
     "start_time": "2021-12-29T21:20:02.976090Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:04.459660Z",
     "start_time": "2021-12-29T21:20:03.555571Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:04.991520Z",
     "start_time": "2021-12-29T21:20:04.819446Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:05.519141Z",
     "start_time": "2021-12-29T21:20:05.349595Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'There are {data_train.isnull().any().sum()}column feature data missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:06.079195Z",
     "start_time": "2021-12-29T21:20:05.877733Z"
    }
   },
   "outputs": [],
   "source": [
    "have_null_fea_dict = (data_train.isnull().sum() / len(data_train)).to_dict()\n",
    "fea_null_moreThanHalf = {}\n",
    "for key, value in have_null_fea_dict.items():\n",
    "    if value > 0.5: \n",
    "        fea_null_moreThanHalf[key] = value\n",
    "fea_null_moreThanHalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:06.986417Z",
     "start_time": "2021-12-29T21:20:06.454253Z"
    }
   },
   "outputs": [],
   "source": [
    "missing = data_train.isnull().sum() / len(data_train) \n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T05:55:50.019385Z",
     "start_time": "2021-12-26T05:55:49.293738Z"
    }
   },
   "outputs": [],
   "source": [
    "one_value_fea = [\n",
    "    col for col in data_train.columns if data_train[col].nunique() <= 1\n",
    "]\n",
    "one_value_fea_test = [\n",
    "    col for col in data_test_a.columns if data_test_a[col].nunique() <= 1\n",
    "]\n",
    "print(\"The feature attribute in the training set has only one value:\", one_value_fea)\n",
    "print(\"Feature attributes in the test set have only one-value features:\", one_value_fea_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T05:55:53.044861Z",
     "start_time": "2021-12-26T05:55:52.943016Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_fea = list(data_train.select_dtypes(exclude=['object']).columns)\n",
    "category_fea = list(\n",
    "    filter(lambda x: x not in numerical_fea, list(data_train.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T05:55:56.440282Z",
     "start_time": "2021-12-26T05:55:56.429361Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T05:56:02.867182Z",
     "start_time": "2021-12-26T05:56:02.863216Z"
    }
   },
   "outputs": [],
   "source": [
    "category_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T05:56:06.380790Z",
     "start_time": "2021-12-26T05:56:06.360811Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.grade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T05:56:45.040692Z",
     "start_time": "2021-12-26T05:56:44.639661Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_numerical_serial_fea(data, feas):\n",
    "    numerical_serial_fea = []\n",
    "    numerical_noserial_fea = []\n",
    "    for fea in feas:\n",
    "        temp = data[fea].nunique() \n",
    "        if temp <= 10:\n",
    "            numerical_noserial_fea.append(fea)\n",
    "            continue\n",
    "        numerical_serial_fea.append(fea)\n",
    "    return numerical_serial_fea, numerical_noserial_fea\n",
    "\n",
    "\n",
    "numerical_serial_fea, numerical_noserial_fea = get_numerical_serial_fea(\n",
    "    data_train, numerical_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T05:56:47.224080Z",
     "start_time": "2021-12-26T05:56:47.216102Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_serial_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T05:56:50.294981Z",
     "start_time": "2021-12-26T05:56:50.290008Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_noserial_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T05:56:52.614278Z",
     "start_time": "2021-12-26T05:56:52.598345Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train['term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T05:56:54.796371Z",
     "start_time": "2021-12-26T05:56:54.784396Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train['homeOwnership'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:01:00.776679Z",
     "start_time": "2021-12-26T05:56:58.236886Z"
    }
   },
   "outputs": [],
   "source": [
    "f = pd.melt(data_train, value_vars=numerical_serial_fea)\n",
    "g = sns.FacetGrid(f, col=\"variable\", col_wrap=2, sharex=False, sharey=False)\n",
    "g = g.map(sns.distplot, \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:01:08.651532Z",
     "start_time": "2021-12-26T06:01:00.992071Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "plt.suptitle('Transaction Values Distribution', fontsize=22)\n",
    "plt.subplot(221)\n",
    "sub_plot_1 = sns.distplot(data_train['loanAmnt'])\n",
    "sub_plot_1.set_title(\"loanAmnt Distribuition\", fontsize=18)\n",
    "sub_plot_1.set_xlabel(\"\")\n",
    "sub_plot_1.set_ylabel(\"Probability\", fontsize=15)\n",
    "\n",
    "plt.subplot(222)\n",
    "sub_plot_2 = sns.distplot(np.log(data_train['loanAmnt']))\n",
    "sub_plot_2.set_title(\"loanAmnt (Log) Distribuition\", fontsize=18)\n",
    "sub_plot_2.set_xlabel(\"\")\n",
    "sub_plot_2.set_ylabel(\"Probability\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:01:08.928992Z",
     "start_time": "2021-12-26T06:01:08.855121Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train['employmentLength'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:01:09.209455Z",
     "start_time": "2021-12-26T06:01:09.133416Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train['issueDate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:01:09.501887Z",
     "start_time": "2021-12-26T06:01:09.426739Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train['earliesCreditLine'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:01:09.716151Z",
     "start_time": "2021-12-26T06:01:09.702188Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train['isDefault'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:01:10.194073Z",
     "start_time": "2021-12-26T06:01:09.914644Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 6))\n",
    "data_train['isDefault'].value_counts().plot.pie(\n",
    "    explode=[0, 0.1], autopct='%1.1f%%', ax=ax[0], shadow=True)\n",
    "ax[0].set_title('isDefault')\n",
    "\n",
    "sns.countplot('isDefault', data=data_train, ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:01:10.794656Z",
     "start_time": "2021-12-26T06:01:10.401418Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.barplot(\n",
    "    data_train[\"employmentLength\"].value_counts(dropna=False)[:20],\n",
    "    data_train[\"employmentLength\"].value_counts(dropna=False).keys()[:20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:01:11.772802Z",
     "start_time": "2021-12-26T06:01:11.001737Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loan_fr = data_train.loc[data_train['isDefault'] == 1]\n",
    "train_loan_nofr = data_train.loc[data_train['isDefault'] == 0]\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 8))\n",
    "train_loan_fr.groupby('grade')['grade'].count().plot(\n",
    "    kind='barh', ax=ax1, title='Count of grade fraud')\n",
    "train_loan_nofr.groupby('grade')['grade'].count().plot(\n",
    "    kind='barh', ax=ax2, title='Count of grade non-fraud')\n",
    "train_loan_fr.groupby('employmentLength')['employmentLength'].count().plot(\n",
    "    kind='barh', ax=ax3, title='Count of employmentLength fraud')\n",
    "train_loan_nofr.groupby('employmentLength')['employmentLength'].count().plot(\n",
    "    kind='barh', ax=ax4, title='Count of employmentLength non-fraud')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:01:12.835467Z",
     "start_time": "2021-12-26T06:01:12.117885Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2)) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "data_train.loc[data_train['isDefault'] == 1] \\\n",
    "    ['loanAmnt'].apply(np.log) \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Log Loan Amt - Fraud',\n",
    "          color='r',\n",
    "          xlim=(-3, 10),\n",
    "         ax= ax1)\n",
    "data_train.loc[data_train['isDefault'] == 0] \\\n",
    "    ['loanAmnt'].apply(np.log) \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Log Loan Amt - Not Fraud',\n",
    "          color='b',\n",
    "          xlim=(-3, 10),\n",
    "         ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:01:13.477699Z",
     "start_time": "2021-12-26T06:01:13.182969Z"
    }
   },
   "outputs": [],
   "source": [
    "total = len(data_train)\n",
    "total_amt = data_train.groupby(['isDefault'])['loanAmnt'].sum().sum()  \n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(121)  \n",
    "plot_tr = sns.countplot(\n",
    "    x='isDefault', data=data_train) \n",
    "plot_tr.set_title(\n",
    "    \"Fraud Loan Distribution \\n 0: good user | 1: bad user\", fontsize=14)\n",
    "plot_tr.set_xlabel(\"Is fraud by count\", fontsize=16)\n",
    "plot_tr.set_ylabel('Count', fontsize=16)\n",
    "for p in plot_tr.patches:\n",
    "    height = p.get_height()\n",
    "    plot_tr.text(\n",
    "        p.get_x() + p.get_width() / 2.,\n",
    "        height + 3,\n",
    "        '{:1.2f}%'.format(height / total * 100),\n",
    "        ha=\"center\",\n",
    "        fontsize=15)\n",
    "\n",
    "percent_amt = (data_train.groupby(['isDefault'])['loanAmnt'].sum())\n",
    "percent_amt = percent_amt.reset_index()\n",
    "plt.subplot(122)\n",
    "plot_tr_2 = sns.barplot(\n",
    "    x='isDefault', y='loanAmnt', dodge=True, data=percent_amt)\n",
    "plot_tr_2.set_title(\n",
    "    \"Total Amount in loanAmnt  \\n 0: good user | 1: bad user\", fontsize=14)\n",
    "plot_tr_2.set_xlabel(\"Is fraud by percent\", fontsize=16)\n",
    "plot_tr_2.set_ylabel('Total Loan Amount Scalar', fontsize=16)\n",
    "for p in plot_tr_2.patches:\n",
    "    height = p.get_height()\n",
    "    plot_tr_2.text(\n",
    "        p.get_x() + p.get_width() / 2.,\n",
    "        height + 3,\n",
    "        '{:1.2f}%'.format(height / total_amt * 100),\n",
    "        ha=\"center\",\n",
    "        fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:02:46.694011Z",
     "start_time": "2021-12-26T06:02:34.527578Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train['issueDate'] = pd.to_datetime(data_train['issueDate'],format='%Y-%m-%d')\n",
    "startdate = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')\n",
    "data_train['issueDateDT'] = data_train['issueDate'].apply(lambda x: x-startdate).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:02:50.240027Z",
     "start_time": "2021-12-26T06:02:47.078946Z"
    }
   },
   "outputs": [],
   "source": [
    "data_test_a['issueDate'] = pd.to_datetime(data_train['issueDate'],format='%Y-%m-%d')\n",
    "startdate = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')\n",
    "data_test_a['issueDateDT'] = data_test_a['issueDate'].apply(lambda x: x-startdate).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:02:58.326759Z",
     "start_time": "2021-12-26T06:02:58.116302Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(data_train['issueDateDT'], label='train')\n",
    "plt.hist(data_test_a['issueDateDT'], label='test')\n",
    "plt.legend()\n",
    "plt.title('Distribution of issueDateDT dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:03:00.987340Z",
     "start_time": "2021-12-26T06:03:00.848641Z"
    }
   },
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(\n",
    "    data_train,\n",
    "    index=['grade'],\n",
    "    columns=['issueDateDT'],\n",
    "    values=['loanAmnt'],\n",
    "    aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:03:03.091212Z",
     "start_time": "2021-12-26T06:03:03.064272Z"
    }
   },
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:03:09.097408Z",
     "start_time": "2021-12-26T06:03:07.188874Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:18:43.590027Z",
     "start_time": "2021-12-26T06:03:10.061229Z"
    }
   },
   "outputs": [],
   "source": [
    "pfr = pandas_profiling.ProfileReport(data_train)\n",
    "pfr.to_file(\"./data visualization.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:08.263116Z",
     "start_time": "2021-12-29T21:20:08.164377Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_fea = list(data_train.select_dtypes(exclude=['object']).columns)\n",
    "category_fea = list(filter(lambda x: x not in numerical_fea,list(data_train.columns)))\n",
    "label = 'isDefault'\n",
    "numerical_fea.remove(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:08.822943Z",
     "start_time": "2021-12-29T21:20:08.622443Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:11.100529Z",
     "start_time": "2021-12-29T21:20:09.183211Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train[numerical_fea] = data_train[numerical_fea].fillna(\n",
    "    data_train[numerical_fea].median())\n",
    "data_test_a[numerical_fea] = data_test_a[numerical_fea].fillna(\n",
    "    data_train[numerical_fea].median())\n",
    "\n",
    "data_train[category_fea] = data_train[category_fea].fillna(\n",
    "    data_train[category_fea].mode())\n",
    "data_test_a[category_fea] = data_test_a[category_fea].fillna(\n",
    "    data_train[category_fea].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:11.659557Z",
     "start_time": "2021-12-29T21:20:11.459062Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:12.017828Z",
     "start_time": "2021-12-29T21:20:12.003839Z"
    }
   },
   "outputs": [],
   "source": [
    "category_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:25.787360Z",
     "start_time": "2021-12-29T21:20:12.407302Z"
    }
   },
   "outputs": [],
   "source": [
    "for data in [data_train, data_test_a]:\n",
    "    data['issueDate'] = pd.to_datetime(data['issueDate'], format='%Y-%m-%d')\n",
    "    startdate = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')\n",
    "    data['issueDateDT'] = data['issueDate'].apply(lambda x: x - startdate).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:28.210247Z",
     "start_time": "2021-12-29T21:20:26.783479Z"
    }
   },
   "outputs": [],
   "source": [
    "def employmentLength_to_int(s):\n",
    "    if pd.isnull(s):\n",
    "        return s\n",
    "    else:\n",
    "        return np.int8(s.split()[0])\n",
    "\n",
    "\n",
    "for data in [data_train, data_test_a]:\n",
    "    data['employmentLength'].replace(\n",
    "        to_replace='10+ years', value='10 years', inplace=True)\n",
    "    data['employmentLength'].replace('< 1 year', '0 years', inplace=True)\n",
    "    data['employmentLength'] = data['employmentLength'].apply(\n",
    "        employmentLength_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:26.316565Z",
     "start_time": "2021-12-29T21:20:26.256516Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train['employmentLength'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:28.630036Z",
     "start_time": "2021-12-29T21:20:28.616048Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train['employmentLength'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:29.225718Z",
     "start_time": "2021-12-29T21:20:29.072086Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:29.665260Z",
     "start_time": "2021-12-29T21:20:29.651296Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train['employmentLength'] = data_train['employmentLength'].fillna(10)\n",
    "\n",
    "data_test_a['employmentLength'] = data_test_a['employmentLength'].fillna(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:30.231817Z",
     "start_time": "2021-12-29T21:20:30.076229Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:30.696034Z",
     "start_time": "2021-12-29T21:20:30.667111Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train['earliesCreditLine'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:31.525757Z",
     "start_time": "2021-12-29T21:20:31.090394Z"
    }
   },
   "outputs": [],
   "source": [
    "for data in [data_train, data_test_a]:\n",
    "    data['earliesCreditLine'] = data['earliesCreditLine'].apply(lambda s: int(s[-4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:32.011668Z",
     "start_time": "2021-12-29T21:20:31.969779Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train['earliesCreditLine'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:32.513857Z",
     "start_time": "2021-12-29T21:20:32.454017Z"
    }
   },
   "outputs": [],
   "source": [
    "cate_features = ['grade', 'subGrade', 'employmentTitle', 'homeOwnership', 'verificationStatus', 'purpose', 'postCode', 'regionCode', \\\n",
    "                 'applicationType', 'initialListStatus', 'title', 'policyCode']\n",
    "for f in cate_features:\n",
    "    print(f, 'Type number：', data[f].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:33.336809Z",
     "start_time": "2021-12-29T21:20:32.949202Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "data_train['grade']=lbl.fit_transform(data_train['grade'])  \n",
    "data_test_a['grade']=lbl.fit_transform(data_test_a['grade'])  \n",
    "data_train['subGrade']=lbl.fit_transform(data_train['subGrade'])  \n",
    "data_test_a['subGrade']=lbl.fit_transform(data_test_a['subGrade']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:35.454101Z",
     "start_time": "2021-12-29T21:20:35.353371Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T07:26:51.283917Z",
     "start_time": "2021-12-29T07:26:50.476078Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(data_train[['subGrade', 'homeOwnership', 'verificationStatus', 'purpose', 'regionCode']])\n",
    "data_train = pd.concat([data_train,dummy], axis = 1)\n",
    "data_train.drop(['subGrade', 'homeOwnership', 'verificationStatus', 'purpose', 'regionCode'], inplace=True, axis = 1)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T07:26:51.698990Z",
     "start_time": "2021-12-29T07:26:51.485561Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(data_test_a[['subGrade', 'homeOwnership', 'verificationStatus', 'purpose', 'regionCode']])\n",
    "data_test_a = pd.concat([data_test_a,dummy], axis = 1)\n",
    "data_test_a.drop(['subGrade', 'homeOwnership', 'verificationStatus', 'purpose', 'regionCode'], inplace=True, axis = 1)\n",
    "data_test_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:30:00.557952Z",
     "start_time": "2021-12-26T06:30:00.539002Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_outliers_by_3segama(data,fea):\n",
    "    data_std = np.std(data[fea])\n",
    "    data_mean = np.mean(data[fea])\n",
    "    outliers_cut_off = data_std * 3\n",
    "    lower_rule = data_mean - outliers_cut_off\n",
    "    upper_rule = data_mean + outliers_cut_off\n",
    "    data[fea+'_outliers'] = data[fea].apply(lambda x:str('abnormal value') if x > upper_rule or x < lower_rule else 'normal value')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:30:14.848120Z",
     "start_time": "2021-12-26T06:30:04.364409Z"
    }
   },
   "outputs": [],
   "source": [
    "for fea in numerical_fea:\n",
    "    data_train = find_outliers_by_3segama(data_train,fea)\n",
    "    print(data_train[fea+'_outliers'].value_counts())\n",
    "    print(data_train.groupby(fea+'_outliers')['isDefault'].sum())\n",
    "    print('='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:30:59.678679Z",
     "start_time": "2021-12-26T06:30:32.798884Z"
    }
   },
   "outputs": [],
   "source": [
    "for fea in numerical_fea:\n",
    "    data_train = data_train[data_train[fea+'_outliers']=='normal value']\n",
    "    data_train = data_train.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T06:51:12.524785Z",
     "start_time": "2021-12-26T06:51:12.279071Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.iloc[:,0:48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T07:27:20.101162Z",
     "start_time": "2021-12-29T07:27:18.934292Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = data_train.drop(['isDefault','issueDate','id'], axis=1)\n",
    "\n",
    "data_corr = x_train.corrwith(data_train.isDefault)\n",
    "result = pd.DataFrame(columns=['features', 'corr'])\n",
    "result['features'] = data_corr.index\n",
    "result['corr'] = data_corr.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T07:28:26.719319Z",
     "start_time": "2021-12-29T07:28:26.702376Z"
    }
   },
   "outputs": [],
   "source": [
    "result['corr'].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:47.543438Z",
     "start_time": "2021-12-29T21:20:47.224815Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = data_train.drop(['issueDate','id','policyCode'], axis=1)\n",
    "data_test_a = data_test_a.drop(['issueDate','id','policyCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:20:50.847647Z",
     "start_time": "2021-12-29T21:20:50.752868Z"
    }
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    f for f in data_train.columns\n",
    "    if f not in ['isDefault'] and '_outliers' not in f\n",
    "]\n",
    "x_train = data_train[features]\n",
    "x_test = data_test_a[features]\n",
    "y_train = data_train['isDefault']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T11:01:41.754599Z",
     "start_time": "2021-12-29T11:01:40.674881Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc_z.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T15:01:03.798969Z",
     "start_time": "2021-12-29T14:59:38.888623Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=1234)\n",
    "\n",
    "AdaBoost1 = ensemble.AdaBoostClassifier()\n",
    "AdaBoost1.fit(X_train, Y_train)\n",
    "pred1 = AdaBoost1.predict(X_test)\n",
    "\n",
    "print('Prediction accuracy of the model in the test set：\\n', metrics.accuracy_score(Y_test, pred1))\n",
    "print('Evaluation report of the model：\\n', metrics.classification_report(Y_test, pred1))\n",
    "print(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T15:02:30.961481Z",
     "start_time": "2021-12-29T15:02:28.875051Z"
    }
   },
   "outputs": [],
   "source": [
    "y_score = AdaBoost1.predict_proba(X_test)[:,1]\n",
    "fpr,tpr,threshold = metrics.roc_curve(Y_test, y_score)\n",
    "roc_auc = metrics.auc(fpr,tpr)\n",
    "\n",
    "plt.stackplot(fpr, tpr, color='steelblue', alpha = 0.5, edgecolor = 'black')\n",
    "\n",
    "plt.plot(fpr, tpr, color='black', lw = 1)\n",
    "\n",
    "plt.plot([0,1],[0,1], color = 'red', linestyle = '--')\n",
    "\n",
    "plt.text(0.5,0.3,'ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "\n",
    "plt.show()\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:54:09.521871Z",
     "start_time": "2021-12-29T16:54:07.413728Z"
    }
   },
   "outputs": [],
   "source": [
    "y_score = AdaBoost1.predict_proba(X_test)[:,1]\n",
    "fpr,tpr,threshold = metrics.roc_curve(Y_test, y_score)\n",
    "\n",
    "roc_auc = metrics.auc(fpr,tpr)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title('Validation ROC')\n",
    "plt.stackplot(fpr, tpr, color='steelblue', alpha = 0.3, edgecolor = 'black')\n",
    "plt.plot(fpr, tpr, 'b', label = 'Val AUC = %0.4f' % roc_auc)\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,1)\n",
    "plt.legend(loc='best')\n",
    "plt.title('ROC')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T15:13:28.516448Z",
     "start_time": "2021-12-29T15:13:27.745442Z"
    }
   },
   "outputs": [],
   "source": [
    "importance = pd.Series(AdaBoost1.feature_importances_, index = x_train.columns)\n",
    "plt.figure(figsize=(8, 16))\n",
    "importance.sort_values().plot(kind = 'barh')\n",
    "plt.show()\n",
    "importance.sort_values(ascending = False).head(10).plot(kind = 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T15:15:43.644750Z",
     "start_time": "2021-12-29T15:15:43.621811Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "pd.set_option('display.max_rows', 130)\n",
    "important_features = pd.DataFrame({'feature':x_train.columns,'importance':AdaBoost1.feature_importances_})\n",
    "important_features.sort_values(by = 'importance',ascending = False,inplace =True)\n",
    "important_features['cum_importance'] = np.cumsum(important_features['importance'])\n",
    "important_features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:21:49.855567Z",
     "start_time": "2021-12-29T21:21:41.383517Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=1234)\n",
    "\n",
    "CART_Class = tree.DecisionTreeClassifier(max_depth=8, min_samples_leaf = 2, min_samples_split=4)\n",
    "\n",
    "decision_tree = CART_Class.fit(X_train, Y_train)\n",
    "\n",
    "pred = CART_Class.predict(X_test)\n",
    "\n",
    "print('Prediction accuracy of the model in the test set:\\n',metrics.accuracy_score(Y_test, pred))\n",
    "print('Evaluation report of the model：\\n',metrics.classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:27:18.020087Z",
     "start_time": "2021-12-29T21:27:11.865328Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "from six import StringIO\n",
    "feature_names=x_train.columns\n",
    "dot_data = tree.export_graphviz(CART_Class, out_file=None, \n",
    "                         feature_names=feature_names,  \n",
    "                         class_names=['0','1'],  \n",
    "                         filled=True, rounded=True, special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T15:29:04.049206Z",
     "start_time": "2021-12-29T15:29:03.835720Z"
    }
   },
   "outputs": [],
   "source": [
    "y_score = decision_tree.predict_proba(X_test)[:,1]\n",
    "fpr,tpr,threshold = metrics.roc_curve(Y_test, y_score)\n",
    "\n",
    "roc_auc = metrics.auc(fpr,tpr)\n",
    "\n",
    "\n",
    "plt.stackplot(fpr, tpr, color='steelblue', alpha = 0.5, edgecolor = 'black')\n",
    "\n",
    "plt.plot(fpr, tpr, color='black', lw = 1)\n",
    "\n",
    "plt.plot([0,1],[0,1], color = 'red', linestyle = '--')\n",
    "\n",
    "plt.text(0.5,0.3,'ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "\n",
    "plt.show()\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:55:00.170177Z",
     "start_time": "2021-12-29T16:54:59.895910Z"
    }
   },
   "outputs": [],
   "source": [
    "y_score = decision_tree.predict_proba(X_test)[:,1]\n",
    "fpr,tpr,threshold = metrics.roc_curve(Y_test, y_score)\n",
    "\n",
    "roc_auc = metrics.auc(fpr,tpr)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title('Validation ROC')\n",
    "plt.stackplot(fpr, tpr, color='steelblue', alpha = 0.3, edgecolor = 'black')\n",
    "plt.plot(fpr, tpr, 'b', label = 'Val AUC = %0.4f' % roc_auc)\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,1)\n",
    "plt.legend(loc='best')\n",
    "plt.title('ROC')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:15:35.778723Z",
     "start_time": "2021-12-29T16:15:34.938433Z"
    }
   },
   "outputs": [],
   "source": [
    "importance = pd.Series(CART_Class.feature_importances_, index = x_train.columns)\n",
    "plt.figure(figsize=(8, 16))\n",
    "importance.sort_values().plot(kind = 'barh')\n",
    "plt.show()\n",
    "importance.sort_values(ascending = False).head(10).plot(kind = 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:16:10.027562Z",
     "start_time": "2021-12-29T16:16:09.998639Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "pd.set_option('display.max_rows', 130)\n",
    "important_features = pd.DataFrame({'feature':x_train.columns,'importance':CART_Class.feature_importances_})\n",
    "important_features.sort_values(by = 'importance',ascending = False,inplace =True)\n",
    "important_features['cum_importance'] = np.cumsum(important_features['importance'])\n",
    "important_features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T15:54:01.410669Z",
     "start_time": "2021-12-29T15:29:25.956891Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = BaggingClassifier(base_estimator=decision_tree, n_estimators=200, random_state=123)\n",
    "tf_tree = model.fit(X_train, Y_train)\n",
    "\n",
    "pred = tf_tree.predict(X_test)\n",
    "print('Prediction accuracy of the model in the test set:',metrics.accuracy_score(Y_test, pred))\n",
    "print('Evaluation report of the model：\\n',metrics.classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:17:28.518620Z",
     "start_time": "2021-12-29T16:17:16.662652Z"
    }
   },
   "outputs": [],
   "source": [
    "y_score = tf_tree.predict_proba(X_test)[:,1]\n",
    "fpr,tpr,threshold = metrics.roc_curve(Y_test, y_score)\n",
    "\n",
    "roc_auc = metrics.auc(fpr,tpr)\n",
    "\n",
    "\n",
    "plt.stackplot(fpr, tpr, color='steelblue', alpha = 0.5, edgecolor = 'black')\n",
    "\n",
    "plt.plot(fpr, tpr, color='black', lw = 1)\n",
    "\n",
    "plt.plot([0,1],[0,1], color = 'red', linestyle = '--')\n",
    "\n",
    "plt.text(0.5,0.3,'ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "\n",
    "plt.show()\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:55:30.834916Z",
     "start_time": "2021-12-29T16:55:19.493154Z"
    }
   },
   "outputs": [],
   "source": [
    "y_score = tf_tree.predict_proba(X_test)[:,1]\n",
    "fpr,tpr,threshold = metrics.roc_curve(Y_test, y_score)\n",
    "\n",
    "roc_auc = metrics.auc(fpr,tpr)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title('Validation ROC')\n",
    "plt.stackplot(fpr, tpr, color='steelblue', alpha = 0.3, edgecolor = 'black')\n",
    "plt.plot(fpr, tpr, 'b', label = 'Val AUC = %0.4f' % roc_auc)\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,1)\n",
    "plt.legend(loc='best')\n",
    "plt.title('ROC')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:06:27.081449Z",
     "start_time": "2021-12-29T16:02:15.470128Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import ensemble\n",
    "\n",
    "RF_class = ensemble.RandomForestClassifier(n_estimators=90,random_state=123)\n",
    "\n",
    "RF_class.fit(X_train, Y_train)\n",
    "\n",
    "RFclass_pred = RF_class.predict(X_test)\n",
    "\n",
    "print('Prediction accuracy of the model in the test set：\\n',metrics.accuracy_score(Y_test, RFclass_pred))\n",
    "print('Evaluation report of the model：\\n',metrics.classification_report(Y_test, RFclass_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:06:55.411215Z",
     "start_time": "2021-12-29T16:06:49.365317Z"
    }
   },
   "outputs": [],
   "source": [
    "y_score = RF_class.predict_proba(X_test)[:,1]\n",
    "fpr,tpr,threshold = metrics.roc_curve(Y_test, y_score)\n",
    "\n",
    "roc_auc = metrics.auc(fpr,tpr)\n",
    "\n",
    "\n",
    "plt.stackplot(fpr, tpr, color='steelblue', alpha = 0.5, edgecolor = 'black')\n",
    "\n",
    "plt.plot(fpr, tpr, color='black', lw = 1)\n",
    "\n",
    "plt.plot([0,1],[0,1], color = 'red', linestyle = '--')\n",
    "\n",
    "plt.text(0.5,0.3,'ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "\n",
    "plt.show()\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:56:08.241626Z",
     "start_time": "2021-12-29T16:55:59.754095Z"
    }
   },
   "outputs": [],
   "source": [
    "y_score = RF_class.predict_proba(X_test)[:,1]\n",
    "fpr,tpr,threshold = metrics.roc_curve(Y_test, y_score)\n",
    "\n",
    "roc_auc = metrics.auc(fpr,tpr)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title('Validation ROC')\n",
    "plt.stackplot(fpr, tpr, color='steelblue', alpha = 0.3, edgecolor = 'black')\n",
    "plt.plot(fpr, tpr, 'b', label = 'Val AUC = %0.4f' % roc_auc)\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,1)\n",
    "plt.legend(loc='best')\n",
    "plt.title('ROC')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:19:31.484491Z",
     "start_time": "2021-12-29T16:19:29.689755Z"
    }
   },
   "outputs": [],
   "source": [
    "importance = pd.Series(RF_class.feature_importances_, index = x_train.columns)\n",
    "plt.figure(figsize=(8, 16))\n",
    "importance.sort_values().plot(kind = 'barh')\n",
    "plt.show()\n",
    "importance.sort_values(ascending = False).head(10).plot(kind = 'barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T16:19:51.312161Z",
     "start_time": "2021-12-29T16:19:51.151557Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "pd.set_option('display.max_rows', 130)\n",
    "important_features = pd.DataFrame({'feature':x_train.columns,'importance':RF_class.feature_importances_})\n",
    "important_features.sort_values(by = 'importance',ascending = False,inplace =True)\n",
    "important_features['cum_importance'] = np.cumsum(important_features['importance'])\n",
    "important_features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T18:07:09.613364Z",
     "start_time": "2021-12-29T18:07:09.571422Z"
    }
   },
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name):\n",
    "    folds = 5\n",
    "    seed = 2020\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print(\n",
    "            '========================================================================================'\n",
    "        )\n",
    "        print(\n",
    "            '****************************************** {} ******************************************'\n",
    "            .format(str(i + 1)))\n",
    "        print(\n",
    "            '========================================================================================'\n",
    "        )\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[\n",
    "            train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'min_child_weight': 5,\n",
    "                'num_leaves': 2**5,\n",
    "                'lambda_l2': 10,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 4,\n",
    "                'learning_rate': 0.1,\n",
    "                'seed': 2020,\n",
    "                'nthread': 28,\n",
    "                'n_jobs': 24,\n",
    "                'silent': True,\n",
    "                'verbose': -1,\n",
    "            }\n",
    "\n",
    "            model = clf.train(\n",
    "                params,\n",
    "                train_matrix,\n",
    "                50000,\n",
    "                valid_sets=[train_matrix, valid_matrix],\n",
    "                verbose_eval=200,\n",
    "                early_stopping_rounds=200)\n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(\n",
    "                test_x, num_iteration=model.best_iteration)\n",
    "\n",
    "            # print(list(sorted(zip(features, model.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True))[:20])\n",
    "\n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.DMatrix(val_x, label=val_y)\n",
    "\n",
    "            params = {\n",
    "                'booster': 'gbtree',\n",
    "                'objective': 'binary:logistic',\n",
    "                'eval_metric': 'auc',\n",
    "                'gamma': 1,\n",
    "                'min_child_weight': 1.5,\n",
    "                'max_depth': 5,\n",
    "                'lambda': 10,\n",
    "                'subsample': 0.7,\n",
    "                'colsample_bytree': 0.7,\n",
    "                'colsample_bylevel': 0.7,\n",
    "                'eta': 0.04,\n",
    "                'tree_method': 'exact',\n",
    "                'seed': 2020,\n",
    "                'nthread': 36,\n",
    "                \"silent\": True,\n",
    "            }\n",
    "\n",
    "            watchlist = [(train_matrix, 'train'), (valid_matrix, 'eval')]\n",
    "\n",
    "            model = clf.train(\n",
    "                params,\n",
    "                train_matrix,\n",
    "                num_boost_round=50000,\n",
    "                evals=watchlist,\n",
    "                verbose_eval=200,\n",
    "                early_stopping_rounds=200)\n",
    "            val_pred = model.predict(\n",
    "                valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            test_pred = model.predict(\n",
    "                test_x, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "        if clf_name == \"cat\":\n",
    "            params = {\n",
    "                'learning_rate': 0.05,\n",
    "                'depth': 5,\n",
    "                'l2_leaf_reg': 10,\n",
    "                'bootstrap_type': 'Bernoulli',\n",
    "                'od_type': 'Iter',\n",
    "                'od_wait': 50,\n",
    "                'random_seed': 11,\n",
    "                'allow_writing_files': False\n",
    "            }\n",
    "\n",
    "            model = clf(iterations=20000, **params)\n",
    "            model.fit(\n",
    "                trn_x,\n",
    "                trn_y,\n",
    "                eval_set=(val_x, val_y),\n",
    "                cat_features=[],\n",
    "                use_best_model=True,\n",
    "                verbose=500)\n",
    "\n",
    "            val_pred = model.predict(val_x)\n",
    "            test_pred = model.predict(test_x)\n",
    "\n",
    "        train[valid_index] = val_pred\n",
    "        test = test_pred / kf.n_splits\n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "\n",
    "        print(cv_scores)\n",
    "\n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T18:07:32.023875Z",
     "start_time": "2021-12-29T18:07:32.009913Z"
    }
   },
   "outputs": [],
   "source": [
    "def lgb_model(x_train, y_train, x_test):\n",
    "    lgb_train, lgb_test = cv_model(lgb, x_train, y_train, x_test, \"lgb\")\n",
    "    return lgb_train, lgb_test\n",
    "\n",
    "def xgb_model(x_train, y_train, x_test):\n",
    "    xgb_train, xgb_test = cv_model(xgb, x_train, y_train, x_test, \"xgb\")\n",
    "    return xgb_train, xgb_test\n",
    "\n",
    "def cat_model(x_train, y_train, x_test):\n",
    "    cat_train, cat_test = cv_model(CatBoostRegressor, x_train, y_train, x_test, \"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T18:13:12.088587Z",
     "start_time": "2021-12-29T18:07:32.510573Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_train, lgb_test = lgb_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T14:31:35.505173Z",
     "start_time": "2021-12-29T14:16:29.222470Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_train, xgb_test = xgb_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T14:54:03.102096Z",
     "start_time": "2021-12-29T14:39:24.357872Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_train, cat_test = cat_model(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T13:24:14.600369Z",
     "start_time": "2021-12-26T13:24:08.008560Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob \n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T13:24:17.835190Z",
     "start_time": "2021-12-26T13:24:17.826214Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show(epochs_range, train_loss, val_loss, train_accuracy, val_accuracy, name):\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, train_accuracy, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.savefig(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-26T13:33:23.973518Z",
     "start_time": "2021-12-26T13:33:23.943566Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_ed = x_train.values.reshape(-1, 15, 5, 1)\n",
    "x_test_ed = x_test.values.reshape(-1, 15, 5, 1)\n",
    "input_dim = (15, 5, 1)\n",
    "nfold = 10\n",
    "kf = KFold(n_splits=nfold, shuffle=True, random_state=2020)\n",
    "prediction1 = np.zeros((1750,20 ))\n",
    "print(prediction1.shape)\n",
    "i = 0\n",
    "for train_index, valid_index in kf.split(x_train_ed, y_train):\n",
    "    print(\"\\nFold {}\".format(i + 1))\n",
    "    train_x, val_x = x_train_ed[train_index],x_train_ed[valid_index]\n",
    "    train_y, val_y = y_train[train_index],y_train[valid_index]\n",
    "    train_x = train_x.reshape(-1, 15, 5, 1)\n",
    "    val_x = val_x.reshape(-1, 15, 5, 1)\n",
    "#     print(train_x.shape)\n",
    "#     print(val_x.shape)\n",
    "#     train_y = to_categorical(train_y)\n",
    "#     val_y = to_categorical(val_y)\n",
    "#     print(train_y.shape)\n",
    "#     print(val_y.shape)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5),padding = \"same\", input_shape=input_dim, activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3),padding = \"same\",activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(256, (3, 3),padding = \"same\",activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='Adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    epochs = 180\n",
    "    history = model.fit(train_x, train_y, epochs = epochs, batch_size = 64, validation_data = (val_x, val_y))\n",
    "    \n",
    "    test_scores = model.evaluate(X_test, Y_test)\n",
    "    epochs_range = range(1, epochs+1)\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    test_loss = test_scores[0]\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    test_acc = test_scores[1]\n",
    "\n",
    "    plot_model(model, to_file=\"model.png\",show_shapes=True);\n",
    "    show(epochs_range, train_loss, val_loss, train_acc, val_acc, 'Model_score_v1')\n",
    "    print('')\n",
    "    print('train loss:', train_loss[-1], '   ', 'train accuracy:', train_acc[-1])\n",
    "    print('val loss:', val_loss[-1], '   ', 'val accuracy:', val_acc[-1])\n",
    "    print('test loss:', test_loss, '   ', 'test accuracy:', test_acc)\n",
    "    print('')\n",
    "    # X_test = np.vstack(X_test)\n",
    "    predictions = model.predict(x_test_ed.reshape(-1, 15, 5, 1))\n",
    "    print(predictions.shape)\n",
    "    prediction1 += ((predictions)) / nfold\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
